{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f9d9130",
   "metadata": {},
   "source": [
    "## visualDet3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b7b3ba58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-ddf1c67763b4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;31m# Build a detector network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0mdetector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDETECTOR_DICT\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetector\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m \u001b[0mdetector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdetector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;31m# Tensor load by GPU\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/theekshana/anaconda3/envs/YOLO3D/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mcuda\u001b[0;34m(self, device)\u001b[0m\n\u001b[1;32m    747\u001b[0m             \u001b[0mModule\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    748\u001b[0m         \"\"\"\n\u001b[0;32m--> 749\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    750\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    751\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mipu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/theekshana/anaconda3/envs/YOLO3D/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    639\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 641\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    642\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    643\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/theekshana/anaconda3/envs/YOLO3D/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    639\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 641\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    642\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    643\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/theekshana/anaconda3/envs/YOLO3D/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    686\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbuf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/theekshana/anaconda3/envs/YOLO3D/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    747\u001b[0m             \u001b[0mModule\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    748\u001b[0m         \"\"\"\n\u001b[0;32m--> 749\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    750\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    751\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mipu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/theekshana/anaconda3/envs/YOLO3D/lib/python3.7/site-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    227\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'CUDA_MODULE_LOADING'\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m             \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'CUDA_MODULE_LOADING'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'LAZY'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m         \u001b[0;31m# Some of the queued calls may reentrantly call _lazy_init();\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m         \u001b[0;31m# we need to just return without initializing in that case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1."
     ]
    }
   ],
   "source": [
    "import sys\n",
    "# sys.path.append(\"../\")\n",
    "import importlib\n",
    "import os\n",
    "import copy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import cython\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision import datasets, models, transforms\n",
    "import torchvision\n",
    "from numba import jit\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "from visualDet3D.data.kitti.utils import write_result_to_file\n",
    "from visualDet3D.utils.utils import LossLogger, cfg_from_file\n",
    "from visualDet3D.networks.utils.registry import DETECTOR_DICT, DATASET_DICT, PIPELINE_DICT\n",
    "from visualDet3D.networks.heads.anchors import Anchors\n",
    "from visualDet3D.networks.lib.fast_utils.hill_climbing import post_opt\n",
    "from visualDet3D.networks.utils import BBox3dProjector, BackProjection\n",
    "from visualDet3D.utils.utils import convertAlpha2Rot, convertRot2Alpha, draw_3D_box, compound_annotation\n",
    "import visualDet3D.data.kitti.dataset\n",
    "from visualDet3D.utils.timer import Timer\n",
    "\n",
    "print('CUDA available: {}'.format(torch.cuda.is_available()))\n",
    "\n",
    "cfg = cfg_from_file(\"config/config.py\")\n",
    "is_test_train = True\n",
    "\n",
    "checkpoint_name = \"Stereo3D_latest.pth\"\n",
    "\n",
    "# Read Conifg File\n",
    "cfg.batch_size=1\n",
    "split_to_test='validation'\n",
    "\n",
    "# Define dataset_name\n",
    "is_test_train = split_to_test == 'training'\n",
    "if split_to_test == 'training':\n",
    "    dataset_name = cfg.data.train_dataset\n",
    "elif split_to_test == 'test':\n",
    "    dataset_name = cfg.data.test_dataset\n",
    "else:\n",
    "    dataset_name = cfg.data.val_dataset\n",
    "\n",
    "# Make dataset\n",
    "dataset = DATASET_DICT[dataset_name](\n",
    "        cfg, split_to_test\n",
    "        )\n",
    "\n",
    "# Split train/validation data\n",
    "if split_to_test=='training':\n",
    "    dataset_val = DATASET_DICT[cfg.data.val_dataset](\n",
    "            cfg, 'validation'\n",
    "            )\n",
    "    dataset.transform = dataset_val.transform\n",
    "    dataset.collate_fn = dataset_val.collate_fn\n",
    "\n",
    "    # Build a detector network\n",
    "detector = DETECTOR_DICT[cfg.detector.name](cfg.detector)\n",
    "detector = detector.cuda()\n",
    "\n",
    "# Tensor load by GPU\n",
    "weight_path = os.path.join(cfg.path.checkpoint_path, checkpoint_name)\n",
    "state_dict = torch.load(weight_path, map_location='cuda:{}'.format(cfg.trainer.gpu))\n",
    "new_dict = state_dict.copy()\n",
    "for key in state_dict:\n",
    "    if 'focalLoss' in key:\n",
    "        new_dict.pop(key)\n",
    "\n",
    "# Load the pre-trained model\n",
    "detector.load_state_dict(new_dict, strict=False)\n",
    "detector.eval().cuda()\n",
    "\n",
    "# Testing pipeline\n",
    "test_func = PIPELINE_DICT[cfg.trainer.test_func]\n",
    "\n",
    "# Load projector and backprojector\n",
    "projector = BBox3dProjector().cuda()\n",
    "backprojector = BackProjection().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "458464f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_bbox2d_to_image(image, bboxes2d, color=(255, 0, 255)):\n",
    "    drawed_image = image.copy()\n",
    "    for box2d in bboxes2d:\n",
    "        cv2.rectangle(drawed_image, (int(box2d[0]), int(box2d[1])), (int(box2d[2]), int(box2d[3])), color, 3)\n",
    "    return drawed_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde74dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(index):\n",
    "    name = \"%06d\" % index\n",
    "    data = dataset[index]\n",
    "    if isinstance(data['calib'], list):\n",
    "        P2 = data['calib'][0]\n",
    "    else:\n",
    "        P2 = data['calib']\n",
    "    original_height = data['original_shape'][0]\n",
    "    collated_data = dataset.collate_fn([data])\n",
    "    height = collated_data[0].shape[2]\n",
    "    scale_2d = (original_height - cfg.data.augmentation.crop_top) / height\n",
    "    \n",
    "    if len(collated_data) > 6:\n",
    "        left_images, right_images, _, _, labels, bbox_3d, _ = collated_data\n",
    "    else:\n",
    "        left_images, right_images, _, _, labels, bbox_3d = collated_data\n",
    "    image = left_images\n",
    "\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        left_images, right_images, P2, P3 = collated_data[0], collated_data[1], collated_data[2], collated_data[3]\n",
    "        scores, bbox, obj_names = detector([left_images.cuda().float().contiguous(),\n",
    "                                          right_images.cuda().float().contiguous(),\n",
    "                                          P2.cuda().float(),\n",
    "                                          P3.cuda().float()])\n",
    "        \n",
    "        P2 = P2[0]\n",
    "        bbox_2d = bbox[:, 0:4]\n",
    "        bbox_3d_state = bbox[:, 4:] #[cx,cy,z,w,h,l,alpha]\n",
    "        bbox_3d_state_3d = backprojector(bbox_3d_state, P2.cuda()) #[x, y, z, w,h ,l, alpha]\n",
    "        abs_bbox, bbox_3d_corner_homo, thetas = projector(bbox_3d_state_3d, P2.cuda())\n",
    "        \n",
    "        rgb_image = denorm(image[0].cpu().numpy().transpose([1, 2, 0]))\n",
    "        \n",
    "        return rgb_image, scores, bbox_2d, obj_names, bbox_3d_corner_homo\n",
    "    \n",
    "#     if len(scores) > 0:\n",
    "#         rgb_image = draw_bbox2d_to_image(rgb_image, bbox_2d.cpu().numpy())\n",
    "#         for box in bbox_3d_corner_homo:\n",
    "#             box = box.cpu().numpy().T\n",
    "#             rgb_image = draw_3D_box(rgb_image, box)\n",
    "#     if is_draw:\n",
    "#         plt.imshow(np.clip(rgb_image, 0, 255))\n",
    "        \n",
    "#     return np.clip(rgb_image, 0, 255)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "785439e6",
   "metadata": {},
   "source": [
    "## tracking + trajectory "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "680b06cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import collections\n",
    "\n",
    "from filterpy.kalman import KalmanFilter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eda2feac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_assignment(cost_matrix):\n",
    "    try:\n",
    "        import lap\n",
    "        _, x, y = lap.lapjv(cost_matrix, extend_cost=True)\n",
    "        return np.array([[y[i],i] for i in x if i >= 0]) #\n",
    "    except ImportError:\n",
    "        from scipy.optimize import linear_sum_assignment\n",
    "        x, y = linear_sum_assignment(cost_matrix)\n",
    "        return np.array(list(zip(x, y)))\n",
    "\n",
    "def iou_batch(bb_test, bb_gt):\n",
    "    \"\"\"\n",
    "    From SORT: Computes IOU between two bboxes in the form [x1,y1,x2,y2]\n",
    "    \"\"\"\n",
    "    bb_gt = np.expand_dims(bb_gt, 0)\n",
    "    bb_test = np.expand_dims(bb_test, 1)\n",
    "\n",
    "    xx1 = np.maximum(bb_test[..., 0], bb_gt[..., 0])\n",
    "    yy1 = np.maximum(bb_test[..., 1], bb_gt[..., 1])\n",
    "    xx2 = np.minimum(bb_test[..., 2], bb_gt[..., 2])\n",
    "    yy2 = np.minimum(bb_test[..., 3], bb_gt[..., 3])\n",
    "    w = np.maximum(0., xx2 - xx1)\n",
    "    h = np.maximum(0., yy2 - yy1)\n",
    "    wh = w * h\n",
    "    o = wh / ((bb_test[..., 2] - bb_test[..., 0]) * (bb_test[..., 3] - bb_test[..., 1])                                      \n",
    "    + (bb_gt[..., 2] - bb_gt[..., 0]) * (bb_gt[..., 3] - bb_gt[..., 1]) - wh)                                              \n",
    "    return(o)  \n",
    "\n",
    "\n",
    "def convert_bbox_to_z(bbox):\n",
    "    \"\"\"\n",
    "    Takes a bounding box in the form [x1,y1,x2,y2] and returns z in the form\n",
    "    [x,y,s,r] where x,y is the centre of the box and s is the scale/area and r is\n",
    "    the aspect ratio\n",
    "    \"\"\"\n",
    "    w = bbox[2] - bbox[0]\n",
    "    h = bbox[3] - bbox[1]\n",
    "    x = bbox[0] + w/2.\n",
    "    y = bbox[1] + h/2.\n",
    "    s = w * h    #scale is just area\n",
    "    r = w / float(h)\n",
    "    return np.array([x, y, s, r]).reshape((4, 1))\n",
    "\n",
    "def convert_x_to_bbox(x,score=None):\n",
    "    \"\"\"\n",
    "    Takes a bounding box in the centre form [x,y,s,r] and returns it in the form\n",
    "    [x1,y1,x2,y2] where x1,y1 is the top left and x2,y2 is the bottom right\n",
    "    \"\"\"\n",
    "    w = np.sqrt(x[2] * x[3])\n",
    "    h = x[2] / w\n",
    "    if(score==None):\n",
    "        return np.array([x[0]-w/2.,x[1]-h/2.,x[0]+w/2.,x[1]+h/2.]).reshape((1,4))\n",
    "    else:\n",
    "        return np.array([x[0]-w/2.,x[1]-h/2.,x[0]+w/2.,x[1]+h/2.,score]).reshape((1,5))\n",
    "\n",
    "def associate_detections_to_trackers(detections,trackers,iou_threshold = 0.3):\n",
    "    \"\"\"\n",
    "    Assigns detections to tracked object (both represented as bounding boxes)\n",
    "\n",
    "    Returns 3 lists of matches, unmatched_detections and unmatched_trackers\n",
    "    \"\"\"\n",
    "    if(len(trackers)==0):\n",
    "        return np.empty((0,2),dtype=int), np.arange(len(detections)), np.empty((0,5),dtype=int)\n",
    "\n",
    "    iou_matrix = iou_batch(detections, trackers)\n",
    "\n",
    "    if min(iou_matrix.shape) > 0:\n",
    "        a = (iou_matrix > iou_threshold).astype(np.int32)\n",
    "        if a.sum(1).max() == 1 and a.sum(0).max() == 1:\n",
    "            matched_indices = np.stack(np.where(a), axis=1)\n",
    "        else:\n",
    "            matched_indices = linear_assignment(-iou_matrix)\n",
    "    else:\n",
    "        matched_indices = np.empty(shape=(0,2))\n",
    "\n",
    "    unmatched_detections = []\n",
    "    for d, det in enumerate(detections):\n",
    "        if(d not in matched_indices[:,0]):\n",
    "            unmatched_detections.append(d)\n",
    "    unmatched_trackers = []\n",
    "    for t, trk in enumerate(trackers):\n",
    "        if(t not in matched_indices[:,1]):\n",
    "            unmatched_trackers.append(t)\n",
    "\n",
    "    #filter out matched with low IOU\n",
    "    matches = []\n",
    "    for m in matched_indices:\n",
    "        if(iou_matrix[m[0], m[1]]<iou_threshold):\n",
    "            unmatched_detections.append(m[0])\n",
    "            unmatched_trackers.append(m[1])\n",
    "        else:\n",
    "            matches.append(m.reshape(1,2))\n",
    "    if(len(matches)==0):\n",
    "        matches = np.empty((0,2),dtype=int)\n",
    "    else:\n",
    "        matches = np.concatenate(matches,axis=0)\n",
    "\n",
    "    return matches, np.array(unmatched_detections), np.array(unmatched_trackers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7d2c1b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KalmanBoxTracker(object):\n",
    "    \"\"\"\n",
    "    This class represents the internal state of individual tracked objects observed as bbox.\n",
    "    \"\"\"\n",
    "    count = 0\n",
    "    def __init__(self,bbox,no_of_past_frames=5,no_of_future_frames=5):\n",
    "        \"\"\"\n",
    "        Initialises a tracker using initial bounding box.\n",
    "        \"\"\"\n",
    "        #define constant velocity model\n",
    "        self.kf = KalmanFilter(dim_x=7, dim_z=4) \n",
    "        self.kf.F = np.array([[1,0,0,0,1,0,0],[0,1,0,0,0,1,0],[0,0,1,0,0,0,1],[0,0,0,1,0,0,0],  [0,0,0,0,1,0,0],[0,0,0,0,0,1,0],[0,0,0,0,0,0,1]])\n",
    "        self.kf.H = np.array([[1,0,0,0,0,0,0],[0,1,0,0,0,0,0],[0,0,1,0,0,0,0],[0,0,0,1,0,0,0]])\n",
    "\n",
    "        self.kf.R[2:,2:] *= 10.\n",
    "        self.kf.P[4:,4:] *= 1000. #give high uncertainty to the unobservable initial velocities\n",
    "        self.kf.P *= 10.\n",
    "        self.kf.Q[-1,-1] *= 0.01\n",
    "        self.kf.Q[4:,4:] *= 0.01\n",
    "\n",
    "        self.kf.x[:4] = convert_bbox_to_z(bbox)\n",
    "        self.time_since_update = 0\n",
    "        self.id = KalmanBoxTracker.count\n",
    "        KalmanBoxTracker.count += 1\n",
    "        self.history = []\n",
    "\n",
    "        self.no_of_past_frames = no_of_past_frames\n",
    "        self.no_of_future_frames = no_of_future_frames\n",
    "        self.update_history = collections.deque(maxlen=self.no_of_past_frames)\n",
    "        self.predict_history = collections.deque(maxlen=self.no_of_future_frames)\n",
    "\n",
    "        self.hits = 0\n",
    "        self.hit_streak = 0\n",
    "        self.age = 0\n",
    "\n",
    "    def update(self,bbox):\n",
    "        \"\"\"\n",
    "        Updates the state vector with observed bbox.\n",
    "        \"\"\"\n",
    "        self.time_since_update = 0\n",
    "        self.history = []\n",
    "        self.hits += 1\n",
    "        self.hit_streak += 1\n",
    "        self.kf.update(convert_bbox_to_z(bbox))\n",
    "        self.update_history.append(bbox)\n",
    "\n",
    "        if  len(self.update_history)>=self.no_of_past_frames :\n",
    "            kbt = KalmanBoxTrajectory(self.update_history[0])\n",
    "            for j in range(1,self.no_of_past_frames):\n",
    "                kbt.predict()\n",
    "                p = kbt.update(self.update_history[j])\n",
    "            for k in range(self.no_of_future_frames):\n",
    "                p = kbt.predict()[0]\n",
    "                self.predict_history.append(p)\n",
    "\n",
    "\n",
    "    def predict(self):\n",
    "        \"\"\"\n",
    "        Advances the state vector and returns the predicted bounding box estimate.\n",
    "        \"\"\"\n",
    "        if((self.kf.x[6]+self.kf.x[2])<=0):\n",
    "          self.kf.x[6] *= 0.0\n",
    "        self.kf.predict()\n",
    "        self.age += 1\n",
    "        if(self.time_since_update>0):\n",
    "          self.hit_streak = 0\n",
    "        self.time_since_update += 1\n",
    "        self.history.append(convert_x_to_bbox(self.kf.x))\n",
    "        return self.history[-1]\n",
    "\n",
    "    def get_state(self):\n",
    "        \"\"\"\n",
    "        Returns the current bounding box estimate.\n",
    "        \"\"\"\n",
    "        return convert_x_to_bbox(self.kf.x)\n",
    "\n",
    "    def get_future_predictions(self):\n",
    "        \"\"\"\n",
    "        Returns the future bounding box estimate.\n",
    "        \"\"\"\n",
    "        return np.array(self.predict_history)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e207e126",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KalmanBoxTrajectory(object):\n",
    "  \"\"\"\n",
    "  This class represents the internal state of individual tracked objects observed as bbox.\n",
    "  \"\"\"\n",
    "  count = 0\n",
    "  def __init__(self,bbox):\n",
    "    \"\"\"\n",
    "    Initialises a tracker using initial bounding box.\n",
    "    \"\"\"\n",
    "    #define constant velocity model\n",
    "    self.kf = KalmanFilter(dim_x=7, dim_z=4) \n",
    "    self.kf.F = np.array([[1,0,0,0,1,0,0],[0,1,0,0,0,1,0],[0,0,1,0,0,0,1],[0,0,0,1,0,0,0],  [0,0,0,0,1,0,0],[0,0,0,0,0,1,0],[0,0,0,0,0,0,1]])\n",
    "    self.kf.H = np.array([[1,0,0,0,0,0,0],[0,1,0,0,0,0,0],[0,0,1,0,0,0,0],[0,0,0,1,0,0,0]])\n",
    "\n",
    "    self.kf.R[2:,2:] *= 10.\n",
    "    self.kf.P[4:,4:] *= 1000. #give high uncertainty to the unobservable initial velocities\n",
    "    self.kf.P *= 10.\n",
    "    self.kf.Q[-1,-1] *= 0.01\n",
    "    self.kf.Q[4:,4:] *= 0.01\n",
    "\n",
    "    self.kf.x[:4] = convert_bbox_to_z(bbox)\n",
    "    self.id = KalmanBoxTrajectory.count\n",
    "    KalmanBoxTrajectory.count += 1\n",
    "    self.history = []\n",
    "\n",
    "  def update(self,bbox):\n",
    "    \"\"\"\n",
    "    Updates the state vector with observed bbox.\n",
    "    \"\"\"\n",
    "    self.history = []\n",
    "    self.kf.update(convert_bbox_to_z(bbox))    \n",
    "\n",
    "  def predict(self):\n",
    "    \"\"\"\n",
    "    Advances the state vector and returns the predicted bounding box estimate.\n",
    "    \"\"\"\n",
    "    if((self.kf.x[6]+self.kf.x[2])<=0):\n",
    "      self.kf.x[6] *= 0.0\n",
    "    self.kf.predict()\n",
    "    self.history.append(convert_x_to_bbox(self.kf.x))\n",
    "    return self.history[-1]\n",
    "\n",
    "  def get_state(self):\n",
    "    \"\"\"\n",
    "    Returns the current bounding box estimate.\n",
    "    \"\"\"\n",
    "    return convert_x_to_bbox(self.kf.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a6ccfd68",
   "metadata": {},
   "outputs": [],
   "source": [
    "#trajectory class\n",
    "class Trajectory(object):\n",
    "  def __init__(self, max_age=1, min_hits=3, iou_threshold=0.3, no_of_future_frames=5, no_of_past_frames=5):\n",
    "    \"\"\"\n",
    "    Sets key parameters for Trajectory\n",
    "    \"\"\"\n",
    "    self.max_age = max_age\n",
    "    self.min_hits = min_hits\n",
    "    self.iou_threshold = iou_threshold\n",
    "    self.trackers = []\n",
    "    self.frame_count = 0\n",
    "\n",
    "    self.no_of_future_frames = no_of_future_frames\n",
    "    self.no_of_past_frames = no_of_past_frames\n",
    "\n",
    "\n",
    "  def update(self, dets=np.empty((0, 5))):\n",
    "    \"\"\"\n",
    "    Params:\n",
    "      dets - a numpy array of detections in the format [[x1,y1,x2,y2,score],[x1,y1,x2,y2,score],...]\n",
    "    Requires: this method must be called once for each frame even with empty detections (use np.empty((0, 5)) for frames without detections).\n",
    "    Returns the a similar array, where the last column is the object ID.\n",
    "\n",
    "    NOTE: The number of objects returned may differ from the number of detections provided.\n",
    "    \"\"\"\n",
    "    self.frame_count += 1\n",
    "    # get predicted locations from existing trackers.\n",
    "    trks = np.zeros((len(self.trackers), 5))\n",
    "    to_del = []\n",
    "    ret = []\n",
    "    for t, trk in enumerate(trks):\n",
    "      pos = self.trackers[t].predict()[0]\n",
    "      trk[:] = [pos[0], pos[1], pos[2], pos[3], 0]\n",
    "      if np.any(np.isnan(pos)):\n",
    "        to_del.append(t)\n",
    "    trks = np.ma.compress_rows(np.ma.masked_invalid(trks))\n",
    "    for t in reversed(to_del):\n",
    "      self.trackers.pop(t)\n",
    "    matched, unmatched_dets, unmatched_trks = associate_detections_to_trackers(dets,trks, self.iou_threshold)\n",
    "\n",
    "    # update matched trackers with assigned detections\n",
    "    for m in matched:\n",
    "      self.trackers[m[1]].update(dets[m[0], :])\n",
    "\n",
    "    # create and initialise new trackers for unmatched detections\n",
    "    for i in unmatched_dets:\n",
    "        trk = KalmanBoxTracker(dets[i,:],self.no_of_past_frames,self.no_of_future_frames)\n",
    "        self.trackers.append(trk)\n",
    "    i = len(self.trackers)\n",
    "    for trk in reversed(self.trackers):\n",
    "        d = trk.get_state()[0] #current bounding box position\n",
    "        fp = trk.get_future_predictions() #future predictions\n",
    "        if (trk.time_since_update < 1) and (trk.hit_streak >= self.min_hits or self.frame_count <= self.min_hits):\n",
    "          ret.append([d,fp, trk.id]) \n",
    "        i -= 1\n",
    "        # remove dead tracklet\n",
    "        if(trk.time_since_update > self.max_age):\n",
    "          self.trackers.pop(i)\n",
    "    if(len(ret)>0):\n",
    "      return np.array(ret)\n",
    "    return np.empty((0,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e79bb1e",
   "metadata": {},
   "source": [
    "## trajectory testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c2541e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd6f4b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create instance of Trajectory\n",
    "mot_tracker = Trajectory() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c41908",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assignTrackID(index):\n",
    "    # get detections\n",
    "    rgb_image, scores, bbox_2d, obj_names, bbox_3d_corner_homo=get_predictions(index)\n",
    "    \n",
    "    if len(scores) > 0:\n",
    "        \n",
    "        detectionsList=[]\n",
    "        for i in range(len(scores)):\n",
    "            detection=np.append((bbox_2d[i]).cpu(),scores[i].cpu())\n",
    "            detectionsList.append(detection)\n",
    "        detectionsNumPyArray = np.asarray(detectionsList)\n",
    "        # update SORT\n",
    "        #  def update(self, dets=np.empty((0, 5))):\n",
    "        \"\"\"\n",
    "            Params:\n",
    "              dets - a numpy array of detections in the format [[x1,y1,x2,y2,score],[x1,y1,x2,y2,score],...]\n",
    "            Requires: this method must be called once for each frame even with empty detections (use np.empty((0, 5)) for frames without detections).\n",
    "            Returns the a similar array, where the last column is the object ID.\n",
    "\n",
    "            NOTE: The number of objects returned may differ from the number of detections provided.\n",
    "        \"\"\"\n",
    "        track_bbs_ids = mot_tracker.update(detectionsNumPyArray)\n",
    "    # track_bbs_ids is a np array where each row contains a valid bounding box and track_id (last column)\n",
    "\n",
    "        for box in bbox_3d_corner_homo:\n",
    "            box = box.cpu().numpy().T\n",
    "            rgb_image = draw_3D_box(rgb_image, box)\n",
    "\n",
    "        track_bbs_ids_list=track_bbs_ids.tolist()\n",
    "        \n",
    "        for j in range(len(track_bbs_ids_list)):\n",
    "            coords = track_bbs_ids_list[j]\n",
    "            x1,y1,x2,y2=int(coords[0]),int(coords[1]),int(coords[2]),int(coords[3])\n",
    "            trackID=int(coords[4])\n",
    "            name=\"ID: {}\".format(str(trackID))\n",
    "\n",
    "            # font\n",
    "            font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "            # org\n",
    "            org = (x1, y1-10)\n",
    "            # fontScale\n",
    "            fontScale = 0.9\n",
    "            # Line thickness of 2 px\n",
    "            thickness = 2\n",
    "            # Blue color in BGR\n",
    "            color=(0, 255, 255)\n",
    "            text_color_bg=(0, 0, 0)\n",
    "            text_size, _ = cv2.getTextSize(name, font, fontScale, thickness)\n",
    "            text_w, text_h = text_size\n",
    "            cv2.rectangle(rgb_image, (x1 , y1-10 - text_h), (x1 + text_w, y1-10), text_color_bg, -1)\n",
    "            \n",
    "            # Using cv2.putText() method\n",
    "            cv2.putText(rgb_image,name, org, font, fontScale, color, thickness, cv2.LINE_AA)\n",
    "\n",
    "                \n",
    "# def draw_bbox2d_to_image(image, bboxes2d, color=(255, 0, 255)):\n",
    "#     drawed_image = image.copy()\n",
    "#     for box2d in bboxes2d:\n",
    "#         cv2.rectangle(drawed_image, (int(box2d[0]), int(box2d[1])), (int(box2d[2]), int(box2d[3])), color, 3)\n",
    "#     return drawed_image\n",
    "            \n",
    "    return np.clip(rgb_image, 0, 255), track_bbs_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b123542",
   "metadata": {},
   "outputs": [],
   "source": [
    "bb_list=[]\n",
    "image_list=[]\n",
    "track_list_all_objects=[]\n",
    "size = 200#837\n",
    "for i in range (size):\n",
    "    print(i)\n",
    "    imagei,track_bbs_ids=assignTrackID(i)\n",
    "    bb=track_bbs_ids[-1,:-1]\n",
    "    bb_list.append(bb)\n",
    "    track_list_all_objects.append(track_bbs_ids)\n",
    "    image_list.append(imagei)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf55ca78",
   "metadata": {},
   "outputs": [],
   "source": [
    "x0_danger_zone=400#300#400\n",
    "x1_danger_zone=800#900#800\n",
    "y0_danger_zone=300\n",
    "y1_danger_zone=200#150#200\n",
    "w_danger_zone=100#150#100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b829a782",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_in_zone(x,y):\n",
    "    if x0<x<x1 and y0>y>y1:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def get_zone_check_point(bb):\n",
    "    x0,y0,x1,y1=bb\n",
    "    if x0<x1_danger_zone:\n",
    "        x=x0\n",
    "    else:\n",
    "        x=x1\n",
    "    y=max(y0,y1)\n",
    "    return x,y\n",
    "\n",
    "def show_zone_warning(image_c,id_list):\n",
    "#     fig = plt.figure(figsize=(16,9))\n",
    "#     clear_output(wait=True)\n",
    "#     draw_danger_zone(image_c)\n",
    "\n",
    "    message= \"Warning! ID:\"+ str(id_list)\n",
    "\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    org = 480,30\n",
    "    fontScale = 1\n",
    "    thickness = 1\n",
    "    color=(255,0,0)\n",
    "\n",
    "    cv2.putText(image_c,message, org, font, fontScale, color, thickness, cv2.LINE_AA)\n",
    "#     plt.imshow(image_c)\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cbd48c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for frame,track in enumerate(track_list):\n",
    "    print('frame',frame)\n",
    "    for vehicle in track:\n",
    "        i=int(vehicle[-1])\n",
    "        bb=vehicle[:-1]\n",
    "        x,y=get_zone_check_point(bb)\n",
    "        if is_in_zone(x,y):\n",
    "            print('Warning!','Frame:',frame,'vehicle ID:',i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e1c761",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.ion()\n",
    "#to show inside notebook \n",
    "%matplotlib inline \n",
    "for frame,track_frame in enumerate(track_list):\n",
    "    id_list=[]\n",
    "    print('frame',frame)\n",
    "    for vehicle in track_frame:\n",
    "        vehicle_ID=int(vehicle[-1])\n",
    "        bb=vehicle[:-1]\n",
    "        x,y=get_zone_check_point(bb)\n",
    "        if is_in_zone(x,y):\n",
    "            id_list.append(vehicle_ID)\n",
    "            print('Warning!','Frame:',frame,'vehicle ID:',id_list)\n",
    "            \n",
    "\n",
    "        image=image_list_c[frame].copy()\n",
    "        draw_danger_zone(image)\n",
    "    if len(id_list)>0:\n",
    "#         clear_output(wait=True) #to show in same window \n",
    "#             plt.close()\n",
    "        show_zone_warning(image,id_list)\n",
    "        fig = plt.figure(figsize=(16,9))\n",
    "        plt.imshow(image)\n",
    "        plt.show()\n",
    "            \n",
    "#     cv2.imwrite(\"data/collision_warning %03d.png\"%frame,cv2.cvtColor(image, cv2.COLOR_RGB2BGR))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
